# -*- coding: utf-8 -*-
"""Recognize Handwritten Digit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wXSmxQLDuEfPXZncb0u1PS7SC8q0V8Mb
"""

!pip install tensorflow

!pip install pillow

"""# Import libraries and dataset"""

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras import backend as K
#  to split the data of training and testing sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

"""# Data Preprocessing

Model cannot take the image data directly so we need to perform some basic operations and process the data to make it ready for our neural network. The dimension of the training data is (60000*28*28). One more dimension is needed for the CNN model so we reshape the matrix to shape (60000* 28* 28*1).
"""

# Assuming you have 10 classes (0-9) for a typical MNIST dataset
num_classes = 10
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
input_shape = (28, 28, 1)
# Conversion of class vectors to matrices of binary class
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

"""# Create the model"""

import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from keras.utils import to_categorical

# Number of classes (assuming MNIST)
num_classes = 10
input_shape = (28, 28, 1)

# Example batch size and epochs
batch_size = 128
epochs = 12

# Define the model
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())  # Flatten the 3D output to 1D
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))  # Output layer with softmax

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# Load and preprocess the data
# Make sure x_train, y_train, x_test, y_test are defined properly
# For example, using the MNIST dataset from Keras:
from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Reshape the data to match the input shape (28, 28, 1)
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)

# Convert class vectors to binary class matrices
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# Normalize input images
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

# Print shapes to verify
print("x_train shape:", x_train.shape)  # Should be (num_samples, 28, 28, 1)
print("y_train shape:", y_train.shape)  # Should be (num_samples, 10)
print("x_test shape:", x_test.shape)    # Should be (num_samples, 28, 28, 1)
print("y_test shape:", y_test.shape)    # Should be (num_samples, 10)

"""# Train the model"""

hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))
print("The model has successfully trained")
model.save('mnist.h5')
print("Saving the model as mnist.h5")

"""# Evaluate the model"""

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])